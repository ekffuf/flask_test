{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from keras.models import load_model\n",
    "from keras.utils import pad_sequences\n",
    "import urllib.parse\n",
    "import os\n",
    "import pickle as pk\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T09:50:31.760190Z",
     "end_time": "2023-06-26T09:50:31.760190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def m4a_wav_convert(path):\n",
    "    encoded_path = urllib.parse.unquote(r\"C:\\Users\\HKIT\\PycharmProjects\\yhdatabase\\203.m4a\")\n",
    "    m4a_file = AudioSegment.from_file(encoded_path, format=\"m4a\", encoding=\"utf-8\")\n",
    "    wav_path = encoded_path.replace(\".m4a\", \".wav\")\n",
    "    m4a_file.export(wav_path, format=\"wav\")\n",
    "    return wav_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T09:50:32.524304Z",
     "end_time": "2023-06-26T09:50:32.535802Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import wave\n",
    "import os\n",
    "\n",
    "def cut_wav(wav_path, start_time, end_time):\n",
    "    # 새로운 WAV 파일 이름 생성\n",
    "    new_wav_path = \"cut_\" + os.path.basename(wav_path)\n",
    "\n",
    "    # 원본 WAV 파일 열기\n",
    "    with wave.open(wav_path, 'rb') as wav_file:\n",
    "        frame_rate = wav_file.getframerate()  # 샘플링 주파수\n",
    "        num_frames = wav_file.getnframes()  # 샘플 수\n",
    "        sample_width = wav_file.getsampwidth()  # 샘플의 바이트 수\n",
    "\n",
    "        start_frame = int(start_time * frame_rate / 1000)  # 시작 프레임\n",
    "        end_frame = int(end_time * frame_rate / 1000)  # 종료 프레임\n",
    "\n",
    "        # 읽을 프레임 범위 설정\n",
    "        wav_file.setpos(start_frame)\n",
    "        frames = wav_file.readframes(end_frame - start_frame)\n",
    "\n",
    "    # 새로운 WAV 파일 생성\n",
    "    with wave.open(new_wav_path, 'wb') as new_wav_file:\n",
    "        new_wav_file.setnchannels(1)  # 모노 오디오\n",
    "        new_wav_file.setsampwidth(sample_width)\n",
    "        new_wav_file.setframerate(frame_rate)\n",
    "        new_wav_file.writeframes(frames)\n",
    "\n",
    "    return new_wav_path\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T09:50:34.057599Z",
     "end_time": "2023-06-26T09:50:34.073223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_wav_duration(wav_path):\n",
    "    with wave.open(wav_path, 'rb') as wav_file:\n",
    "        frame_rate = wav_file.getframerate()  # 샘플링 주파수\n",
    "        num_frames = wav_file.getnframes()  # 샘플 수\n",
    "\n",
    "    duration_in_ms = (num_frames / frame_rate) * 1000  # 밀리초 단위로 계산\n",
    "    return int(duration_in_ms)  # 정수형으로 반환\n",
    "\n",
    "def stt(wav):\n",
    "    # 파일로부터 음성 불러오기, STT 변환\n",
    "    r = sr.Recognizer()\n",
    "    real = \"\"\n",
    "\n",
    "    # 파일을 총 음원 길이로 나누어서 처리\n",
    "    total_duration = get_wav_duration(wav)  # WAV 파일의 총 음원 길이를 가져옴 (밀리초 단위)\n",
    "    split_duration = 120000  # 쪼갤 음원 길이 (밀리초 단위)\n",
    "    num_splits = math.ceil(total_duration / split_duration)  # 총 쪼갤 개수\n",
    "\n",
    "    # 음원을 쪼개어 변환\n",
    "    for i in range(num_splits):\n",
    "        start_time = i * split_duration  # 시작 시간\n",
    "        end_time = min((i + 1) * split_duration, total_duration)  # 종료 시간\n",
    "\n",
    "        split_wav = cut_wav(wav, start_time, end_time)  # 음원 쪼개기\n",
    "\n",
    "        with sr.AudioFile(split_wav) as source:\n",
    "            audio = r.record(source)\n",
    "\n",
    "        r_text = r.recognize_google(audio, language='ko')\n",
    "        real += r_text\n",
    "\n",
    "    return real\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T09:50:35.260134Z",
     "end_time": "2023-06-26T09:50:35.275002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-26T09:39:53.584934Z",
     "end_time": "2023-06-26T09:39:53.600592Z"
    }
   },
   "outputs": [
    {
     "ename": "RequestError",
     "evalue": "recognition request failed: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:708\u001B[0m, in \u001B[0;36mRecognizer.recognize_google\u001B[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001B[0m\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 708\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moperation_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py:216\u001B[0m, in \u001B[0;36murlopen\u001B[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[0;32m    215\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[1;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py:525\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[1;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[0;32m    524\u001B[0m     meth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(processor, meth_name)\n\u001B[1;32m--> 525\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mmeth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py:634\u001B[0m, in \u001B[0;36mHTTPErrorProcessor.http_response\u001B[1;34m(self, request, response)\u001B[0m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m):\n\u001B[1;32m--> 634\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttp\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhdrs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py:563\u001B[0m, in \u001B[0;36mOpenerDirector.error\u001B[1;34m(self, proto, *args)\u001B[0m\n\u001B[0;32m    562\u001B[0m args \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mdict\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp_error_default\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m orig_args\n\u001B[1;32m--> 563\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py:496\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[1;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[0;32m    495\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[1;32m--> 496\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py:643\u001B[0m, in \u001B[0;36mHTTPDefaultErrorHandler.http_error_default\u001B[1;34m(self, req, fp, code, msg, hdrs)\u001B[0m\n\u001B[0;32m    642\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_error_default\u001B[39m(\u001B[38;5;28mself\u001B[39m, req, fp, code, msg, hdrs):\n\u001B[1;32m--> 643\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(req\u001B[38;5;241m.\u001B[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001B[1;31mHTTPError\u001B[0m: HTTP Error 400: Bad Request",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRequestError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m             audio \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mrecord(source)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;66;03m#r_text = r.recognize_google(audio, language='ko-KR')\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m     real \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecognize_google\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlanguage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mko-KR\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(real)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:710\u001B[0m, in \u001B[0;36mRecognizer.recognize_google\u001B[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001B[0m\n\u001B[0;32m    708\u001B[0m     response \u001B[38;5;241m=\u001B[39m urlopen(request, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moperation_timeout)\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 710\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RequestError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecognition request failed: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e\u001B[38;5;241m.\u001B[39mreason))\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m URLError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RequestError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecognition connection failed: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e\u001B[38;5;241m.\u001B[39mreason))\n",
      "\u001B[1;31mRequestError\u001B[0m: recognition request failed: Bad Request"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "real = \"\"\n",
    "total_duration = 120000  # 총 음원 길이 (밀리세컨드)\n",
    "split_duration = 120000  # 쪼갤 음원 길이 (밀리세컨드)\n",
    "num_splits = math.ceil(total_duration / split_duration)  # 총 쪼갤 개수\n",
    "\n",
    "for i in range(num_splits):\n",
    "    start_time = i * split_duration  # 시작 시간\n",
    "    end_time = min((i + 1) * split_duration, total_duration)  # 종료 시간\n",
    "\n",
    "    split_wav = wav_path[start_time:end_time]  # 음원 쪼개기\n",
    "\n",
    "    with sr.AudioFile(split_wav) as source:\n",
    "            audio = r.record(source)\n",
    "\n",
    "    #r_text = r.recognize_google(audio, language='ko-KR')\n",
    "    real += r.recognize_google(audio, language='ko-KR')\n",
    "print(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytaglib\n",
      "  Downloading pytaglib-2.0.0-cp310-cp310-win_amd64.whl (227 kB)\n",
      "     -------------------------------------- 227.5/227.5 kB 6.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pytaglib\n",
      "Successfully installed pytaglib-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytaglib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T10:28:48.332859Z",
     "end_time": "2023-06-26T10:28:53.724401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import taglib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T10:29:38.946505Z",
     "end_time": "2023-06-26T10:29:38.959648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "807"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = taglib.File(r\"C:\\Users\\HKIT\\PycharmProjects\\yhdatabase\\882.wav\")\n",
    "\n",
    "song.length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T10:33:58.177938Z",
     "end_time": "2023-06-26T10:33:58.240411Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Given audio file must be a filename string or a file-like object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 27\u001B[0m\n\u001B[0;32m     24\u001B[0m cut_audio \u001B[38;5;241m=\u001B[39m cut_audio(audio_path, start_time, end_time)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# 음원 STT 변환\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m transcribed_text \u001B[38;5;241m=\u001B[39m \u001B[43mtranscribe_audio\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcut_audio\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# 변환된 텍스트 이어붙이기\u001B[39;00m\n\u001B[0;32m     30\u001B[0m text_list \u001B[38;5;241m=\u001B[39m [transcribed_text, transcribed_text]  \u001B[38;5;66;03m# 여러 개의 텍스트가 있다면 리스트에 추가\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[32], line 11\u001B[0m, in \u001B[0;36mtranscribe_audio\u001B[1;34m(audio_path)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtranscribe_audio\u001B[39m(audio_path):\n\u001B[0;32m     10\u001B[0m     r \u001B[38;5;241m=\u001B[39m sr\u001B[38;5;241m.\u001B[39mRecognizer()\n\u001B[1;32m---> 11\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43msr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAudioFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio_path\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m source:\n\u001B[0;32m     12\u001B[0m         audio \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mrecord(source)\n\u001B[0;32m     13\u001B[0m     text \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mrecognize_google(audio, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mko-KR\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:226\u001B[0m, in \u001B[0;36mAudioFile.__init__\u001B[1;34m(self, filename_or_fileobject)\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename_or_fileobject):\n\u001B[1;32m--> 226\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filename_or_fileobject, (\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(filename_or_fileobject, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGiven audio file must be a filename string or a file-like object\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    227\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilename_or_fileobject \u001B[38;5;241m=\u001B[39m filename_or_fileobject\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mAssertionError\u001B[0m: Given audio file must be a filename string or a file-like object"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "\n",
    "def cut_audio(audio_path, start_time, end_time):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    cut_audio = audio[start_time:end_time]\n",
    "    return cut_audio\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "    text = r.recognize_google(audio, language='ko-KR')\n",
    "    return text\n",
    "\n",
    "def concatenate_texts(text_list):\n",
    "    concatenated_text = ' '.join(text_list)\n",
    "    return concatenated_text\n",
    "\n",
    "# 음원 길이 자르기\n",
    "audio_path = r\"C:\\Users\\HKIT\\PycharmProjects\\yhdatabase\\882.wav\"\n",
    "start_time = 0  # 자르기 시작 시간 (밀리초)\n",
    "end_time = 30000  # 자르기 종료 시간 (밀리초)\n",
    "cut_audio = cut_audio(audio_path, start_time, end_time)\n",
    "\n",
    "# 음원 STT 변환\n",
    "transcribed_text = transcribe_audio(cut_audio)\n",
    "\n",
    "# 변환된 텍스트 이어붙이기\n",
    "text_list = [transcribed_text, transcribed_text]  # 여러 개의 텍스트가 있다면 리스트에 추가\n",
    "concatenated_text = concatenate_texts(text_list)\n",
    "\n",
    "print(concatenated_text)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공구 점핑 000 아니 지금 이게 여러가지 운동할 수 있다는 거죠네 맞습니다 아 이거는 자동 주문이 안 되네요 제가 등록이 안 된다고 그러는데요 지금 자동 주문 하셨는데요 등록이 안 돼서 아마 상담사 연결 된 것 같습니다 공구 점핑 000 아니 지금 이게 여러가지 운동할 수 있다는 거죠네 맞습니다 아 이거는 자동 주문이 안 되네요 제가 등록이 안 된다고 그러는데요 지금 자동 주문 하셨는데요 등록이 안 돼서 아마 상담사 연결 된 것 같습니다\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "\n",
    "def cut_audio(audio_path, start_time, end_time):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    cut_audio = audio[start_time:end_time]\n",
    "    return cut_audio\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "    text = r.recognize_google(audio, language='ko-KR')\n",
    "    return text\n",
    "\n",
    "def concatenate_texts(text_list):\n",
    "    concatenated_text = ' '.join(text_list)\n",
    "    return concatenated_text\n",
    "\n",
    "# 음원 길이 자르기\n",
    "audio_path = r\"C:\\Users\\HKIT\\PycharmProjects\\yhdatabase\\882.wav\"\n",
    "start_time = 0  # 자르기 시작 시간 (밀리초)\n",
    "end_time = 30000  # 자르기 종료 시간 (밀리초)\n",
    "cut_audio = cut_audio(audio_path, start_time, end_time)\n",
    "\n",
    "# 잘린 음원을 임시 파일로 저장\n",
    "cut_audio.export(\"cut_audio.wav\", format=\"wav\")\n",
    "\n",
    "# 잘린 음원 STT 변환\n",
    "transcribed_text = transcribe_audio(\"cut_audio.wav\")\n",
    "\n",
    "# 변환된 텍스트 이어붙이기\n",
    "text_list = [transcribed_text, transcribed_text]  # 여러 개의 텍스트가 있다면 리스트에 추가\n",
    "concatenated_text = concatenate_texts(text_list)\n",
    "\n",
    "print(concatenated_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T10:47:41.656927Z",
     "end_time": "2023-06-26T10:47:45.823416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 17\u001B[0m\n\u001B[0;32m     13\u001B[0m     ny \u001B[38;5;241m=\u001B[39m y[start_time \u001B[38;5;241m*\u001B[39m sr:sr \u001B[38;5;241m*\u001B[39m (sec \u001B[38;5;241m+\u001B[39m start_time)]\n\u001B[0;32m     14\u001B[0m     sf\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_time\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m, ny, sr)\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43maudio_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwav\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     18\u001B[0m     audio_file \u001B[38;5;241m=\u001B[39m wav_path\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m#save_file = wav_path + \"\\\\\" + \"wav\" + \"\\\\\" + audio_name[:-4]\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "audio_list = os.listdir(r\"C:\\Users\\HKIT\\PycharmProjects\\yhdatabase\")\n",
    "wav_path = r\"C:\\Users\\HKIT\\PycharmProjects\\yhdatabase\\55.wav\"\n",
    "\n",
    "\n",
    "def trim_audio_data(audio_file, start_time=0.0):\n",
    "    sr = 44100\n",
    "    y, sr = librosa.load(audio_file, sr=sr)\n",
    "    sec = int(librosa.get_duration(y=y, sr=sr))\n",
    "    ny = y[start_time * sr:sr * (sec + start_time)]\n",
    "    sf.write(f\"_{start_time}.wav\", ny, sr)\n",
    "\n",
    "\n",
    "if audio_list.find('wav') != -1:\n",
    "    audio_file = wav_path\n",
    "    #save_file = wav_path + \"\\\\\" + \"wav\" + \"\\\\\" + audio_name[:-4]\n",
    "    f = sf.SoundFile(audio_file)\n",
    "    f_sec = f.frames // f.samplerate\n",
    "    print(audio_file, \" seconds, \", f_sec)\n",
    "\n",
    "    sec = 30\n",
    "    for i in range(f_sec - sec):\n",
    "        if i * 30 > f_sec:\n",
    "            break\n",
    "        trim_audio_data(audio_file, start_time=i * 30)\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(wav_path) as source:\n",
    "    audio = r.record(source)\n",
    "text = r.recognize_google(audio, language='ko-KR')\n",
    "\n",
    "concatenated_text = ' '.join(text_list)\n",
    "print(concatenated_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
